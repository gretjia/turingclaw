# LLM_PROVIDER:
# - gemini_cli  -> Use local Gemini CLI OAuth session (no GEMINI_API_KEY required)
# - codex_cli   -> Use local Codex CLI OAuth session (no OPENAI API key required)
# - kimi_api    -> Use Kimi Code API (OpenAI-compatible endpoint)
# - gemini_api  -> Use Gemini API key directly
# If omitted, engine auto-detects in this order: gemini_cli -> codex_cli -> kimi_api -> gemini_api.
LLM_PROVIDER="gemini_cli"

# LLM_MODEL (optional): shared model override used by all providers unless provider-specific value is set.
# Example: LLM_MODEL="gemini-3-pro-preview"
LLM_MODEL=""

# GEMINI_MODEL (optional): overrides LLM_MODEL for Gemini provider (CLI and API).
GEMINI_MODEL=""

# CODEX_MODEL (optional): overrides LLM_MODEL for Codex CLI provider.
CODEX_MODEL=""

# KIMI_MODEL / KIMI_BASE_URL:
# Defaults:
# - KIMI_MODEL="kimi-for-coding"
# - KIMI_BASE_URL="https://api.kimi.com/coding/v1"
# - KIMI_ANTHROPIC_VERSION="2023-06-01"
KIMI_MODEL=""
KIMI_BASE_URL="https://api.kimi.com/coding/v1"
KIMI_ANTHROPIC_VERSION="2023-06-01"
KIMI_MAX_TOKENS="4096"

# Execution guardrails inspired by OpenClaw community practices:
# - full: allow all commands (default), but dangerous commands still require approval token.
# - allowlist: only commands in TURING_EXEC_ALLOWLIST are allowed by default.
# - deny: disable <EXEC> command execution.
TURING_EXEC_SECURITY="full"

# Additional approval behavior:
# - off: no extra approval for non-allowlist commands.
# - on-miss: non-allowlist command needs [APPROVE_EXEC] in the user message.
# - always: every command needs [APPROVE_EXEC].
TURING_EXEC_ASK="off"

# Comma-separated command allowlist used by TURING_EXEC_SECURITY=allowlist or TURING_EXEC_ASK=on-miss.
TURING_EXEC_ALLOWLIST=""

# Dangerous command protection (kill/pkill/reboot/shutdown/rm -rf...):
# if true, requires [APPROVE_DANGEROUS] in the latest user message.
TURING_REQUIRE_DANGEROUS_APPROVAL="true"

# mock_ssh is simulation-only by default. Keep false for real operations.
TURING_ALLOW_MOCK_SSH="false"

# Host target guardrail:
# Commands targeting non-authorized IPs require [ALLOW_UNLISTED_HOST].
TURING_VALIDATE_IP_TARGETS="true"
# Optional source-of-truth host files (comma-separated). First non-empty file wins.
# If TURING_TASK_ID is enabled, point the second path to that task workspace memory file.
TURING_HOST_SOT_PATHS="/path/to/handover/LATEST.md,/path/to/turingclaw/workspace/memory/host_config.md"
# Personal host/project paths belong in local .env only.

# Optional handover bootstrap files/folders (comma-separated):
# Engine scans these sources (plus TURING_ENTRY_HINT paths) and writes:
# - memory/handover_index.md (what was scanned)
# - memory/ssh_runtime.env (SSH runtime vars for skills/remote_mgr.py)
TURING_HANDOVER_PATHS="/path/to/handover/ai-direct/LATEST.md,/path/to/handover"

# Optional direct SSH overrides (highest priority; keep in local .env only):
TURING_SSH_USER=""
TURING_SSH_KEY=""
TURING_SSH_PORT="22"
TURING_SSH_STRICT="no"

# Hard host scope guardrail:
# If set, any IP outside this list is blocked unless [APPROVE_HOST_SWITCH] is in latest user message.
# Example (Windows-only): TURING_SCOPE_HOSTS="192.168.1.10"
TURING_SCOPE_HOSTS=""

# Task-isolated workspace (prevents cross-task TAPE contamination):
# - TURING_TASK_ID: stable isolated workspace key, stored under TURING_WORKSPACE_ROOT.
# - TURING_WORKSPACE_ISOLATE=true: auto-create unique workspace per process if TURING_TASK_ID is empty.
# - TURING_WORKSPACE_DIR: explicit absolute/relative workspace path (highest priority override).
TURING_WORKSPACE_ROOT="./workspace-runs"
TURING_TASK_ID=""
TURING_WORKSPACE_ISOLATE="false"
TURING_WORKSPACE_DIR=""

# Anti-runaway turn budget (prevents infinite loops / token burn per user message)
TURING_MAX_TURNS_PER_RUN="40"
# Immutable ROM lines at top of TAPE (goal/scope cannot be erased by <ERASE>)
TURING_ROM_LINES="15"
# Stagnation detector scan window (chars from end of tape)
TURING_STAGNATION_WINDOW_CHARS="2000"

# GEMINI_API_KEY / GOOGLE_API_KEY:
# Only required when LLM_PROVIDER=gemini_api.
GEMINI_API_KEY="MY_GEMINI_API_KEY"
GOOGLE_API_KEY=""

# KIMI_API_KEY:
# Required when LLM_PROVIDER=kimi_api.
KIMI_API_KEY=""

# APP_URL: The URL where this applet is hosted.
# AI Studio automatically injects this at runtime with the Cloud Run service URL.
# Used for self-referential links, OAuth callbacks, and API endpoints.
APP_URL="MY_APP_URL"
